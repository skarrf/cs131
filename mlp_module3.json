{
  "input_layer": {
    "shape": "None"
  },
  "hidden_layer": {
    "num_layers": 2,
    "num_nodes": 64,
    "activation": "relu"
  },
  "output_layer": {
    "size": 1,
    "activation": "sigmoid"
  }
}
